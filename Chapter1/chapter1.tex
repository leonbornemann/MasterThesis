%*******************************************************************************
%*********************************** First Chapter *****************************
%*******************************************************************************

\chapter{Introduction}  %Title of the First Chapter

\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi

Almost any application domain of information systems has some data that is being generated. In many cases this data contains valuable knowledge which can be learned or extracted from it. For example correlations like \textit{"95\% of all patients that were treated with medication B complained about severe headaches in the following days"} or \textit{"four out of five users who liked the movie Dr. Strange also liked Captain America: Civil War"} clearly represent valuable knowledge for their respective domains. Of course, the time of manual data processing has long since passed as automated, algorithmic solutions were discovered. The field of research that deals with these approaches and algorithms has many different names and subareas with sometimes subtle differences, ranging from data mining, data analytics and data analysis to machine learning or business intelligence to only name a few. \\
The underlying data, which is processed to reveal knowledge can of course take many forms. One very general form of data are data streams. Data streams are not limited to the recent rise in popularity of video and audio streams. On the contrary the application domains that produce data in the form of streams are very diverse. They include for example constantly running business applications that log business activities and events, sensor networks that report usage data or devices that take measurements of physical quantities (such as temperature, pressure, humidity, etc...) at certain points of time. \\
The fact that streams generate a constant stream of data and thus lead to a constantly growing amount of data is a significant difference to classic applications of data mining in which there is a static (training) database. Despite that significant difference, many fields of interest in the context of static databases are also of interest for data streams. Approaches and algorithms that solve problems for static databases, while by no means fully researched, are rather well known and evaluated. Applying these methods to data streams can present challenges and may demand many modifications due to the large and possibly infinite amounts of data produced by streams. Naturally, data mining methods for stream data must be especially fast, scalable and memory efficient. \newline
Apart from the additional, algorithmic constraints on memory and computation time, data streams also present conceptual challenges. In contrast to static databases, streams may evolve over time, which can make it very difficult for algorithms to assess which historical data of the stream should be considered when analyzing the currently incoming data. Recognizing these so called concept drifts is one challenge among many when processing or mining data streams. \newline
A suitable way to look at most data streaming scenarios is that of event streams. An event can be basically anything that happens in the real world, represented as an element of a data stream. Examples of this could be a rise in temperature that is reported by a sensor or an increase in the value of a stock that is being traded at a stock market. In the context of event processing these events are commonly referred to as basic or simple events. \newline
A more advanced form of events are complex events. Complex events are structures that consist of multiple basic events with different relationships between each other. Discovering interesting complex event patterns can be tough, especially since there may be a lot of potential candidates. The discovery of complex events is related to the research area of pattern mining, since complex events are essentially large patterns that are mined from basic events. Traditionally, pattern mining is an area of data mining that is often employed to extract knowledge or interesting correlations. Discovering interesting complex events in an event stream is called complex event pattern mining. In addition to the underlying event stream, it is often also useful to use semantic knowledge to improve or extend the results of the mining process. Semantic knowledge is essentially additional information about the events present in the stream. Simple domain knowledge like \textit{"Sensor A was built by company XY"} or \textit{"Company A belongs to the IT-Sector"} can have big implications for the interestingness of patterns. When additional domain knowledge is considered in the mining process this can be referred to as semantic complex event pattern mining. \\
Since the term of complex events is very broad, this thesis will focus on the subtopic of episode patterns. Episodes are complex events in which single events or entire episodes can be combined using two operators: the conjunction and the sequence operator. Figure \ref{fig_simpleEpisodeExample} visualizes a simple episode pattern and example occurrences in a data stream.

\begin{figure}[h]
	\centering
  	\includegraphics[width=0.5\textwidth]{exampleEpisode.jpg}
	\caption[Example Episode Pattern and Occurrences]{The top half visualizes an example episode pattern, which consist of a conjunction (A and B must both occur, but the order does not matter) and a sequence (C must occur after A and B). The bottom half shows two windows of an example stream, in which occurrences of the episode are shown in green.}
	\label{fig_simpleEpisodeExample}
\end{figure}

Episodes are sequential patterns that have previously been mined from very long sequences, which makes them an appropriate mining target in event streams, since streams and sequences share the sequential nature. The only difference is that streams grow over time, whereas sequences have a fixed size.\\
So why should one be interested in complex events or episodes? What benefit does the discovery or recognition of such structures in a data stream have? While there are indeed many uses for the discovery of complex events this thesis will focus on one specific application: Prediction. The prediction of certain events in an ongoing event stream has many obvious use cases such as building early warning systems for hazardous events like power outages in power grids, failures in sensor networks or even natural disasters, such as earthquakes. Prediction in itself is of course a widely researched topic, but building predictive models for an event stream, based on previously mined episodes has only received limited attention so far.
The idea of combining these two research area is rather simple. I aim to mine complex events from an event stream with the specific purpose of predicting future occurrences of a specific event type. \newline
Figure \ref{fig_approach} summarizes the goal of this thesis graphically. The underlying event stream is mined for complex events by a mining algorithm that will consider the information given in the stream but may also include additional semantic knowledge. The resulting complex events are then used as input for a model building algorithm, which will produce a predictive model. Afterwards this model can be used to predict occurrences of certain events in the original (still ongoing) event stream.
\begin{figure}[h]
	\centering
  	\includegraphics[width=0.5\textwidth]{approach.jpg}
	\caption[Goal of this Thesis]{General Structure of the approach suggested by this thesis.}
	\label{fig_approach}
\end{figure}

The domain that will be used in the evaluation of this thesis is stock market prediction. Both predicting the overall direction of the stock market and predicting whether individual stocks will rise or fall are a difficult problems that have the obvious application of making profitable investments. \newline
The rest of the thesis is outlined as follows: Chapter \ref{chapter_related} introduces the basic terminology and reviews the related work, Chapter \ref{chapter_background} follows up with formal definitions and a more detailed introduction to episode mining. Chapter \ref{chapter_solutions} presents the suggested algorithms to mine predictive models for event streams using episodes and analyzes their complexities. Chapter \ref{chapter_proofOfConcept} then briefly presents the implementation and justifies the software design decisions. Subsequently chapter \ref{chapter_evaluation} presents an extensive evaluation using real stock market data. Finally chapter \ref{chapter_conclusion} concludes the paper and mentions possible future work.